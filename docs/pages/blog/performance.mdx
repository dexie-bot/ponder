---
title: "Ponder Performance"
description: "A blog post about performance in Ponder."
---

import { Benchmarks } from "@/components/Benchmarks";
import { Callout } from "nextra/components";

# Ponder Performance

Delivering peak performance has been a driving principle for Ponder throughout its almost three-year history, and the central theme of our focused work in recent months. We're happy to share what makes Ponder fast and what we learned along the way.

```
Ponder   █ 41s (95.2x faster)

TheGraph ████████████████████████████████████████████████████████████████████████ 1h 5m 
```
> This is a benchmark of the `reference-erc20` app running from blocks 13000000 to 20000000 on an M4 Macbook Air.
> TheGraph is a popular and original indexing framework for Ethereum. 

Performance is very important for a framework like Ponder, because it allows developers to rapidly and freely iterate, focusing on their business logic instead of restraints introduced by the tool. Over time, this creates faster feedback loops and better end user expiriences.

Ponder is built with TypeScript. This choice is deliberate, but it might be a surprise to some expecting us to _Rewrite-it-in-Rust_. Ponder is proof that thoughtful architecture design allows us to deliver great performance without leaving the comfort of the JavaScript ecosystem.

We use a combination of unit benchmarks, metrics, and flamegraphs to identify performance bottlenecks and measure the impact of changes.

## Overview of Ponder architecture

To start, a review of the architecture of Ponder. Ponder is an [ETL framework](https://en.wikipedia.org/wiki/Extract,_transform,_load). It **extracts** data from an Ethereum node through the JSON-RPC API, **transforms** the data with user-defined indexing functions, and **loads** the results into postgres for persistent storage.

Internally, a Ponder app has two main phases. The **historical backfill** indexes events from the desiginated "start" of the app up to the current point in time. Then, the **realtime** phase indexes newly produced blocks, processing them immediately.

Ethereum blocks, transactions, traces, logs, and events logically grouped together are collectively referred to as **events**. The simplified goal of any performance work is to increase the number of events processed per second across a diverse range of user workloads.

## Performance optimizations

The following examples highlight key optimizations, particularly within our data 'transform' step, but they're just a part of our overall performance work. The key bottlenecks in this step are 1) database queries, when user logic requires reading data that's already been inserted and 2) RPC requests.

### In-memory indexing

The transform step runs user-defined indexing functions, such as the one from our [ERC20 example](https://github.com/ponder-sh/ponder/blob/main/examples/reference-erc20/src/index.ts) below. An indexing function commonly has one or many database function calls for writing application ready data to the database.

Ponder has a [store API](https://ponder.sh/docs/indexing/write-to-the-database#store-api) made up of `find()`, `insert()`, `update()`, and `delete()` for simplified database access. If that is too constrained, [raw SQL](https://ponder.sh/docs/indexing/write-to-the-database#raw-sql) is also available.

```ts filename="src/index.ts" {6, 16}
import { ponder } from "ponder:registry";
import { allowance, approvalEvent } from "ponder:schema";

ponder.on("ERC20:Approval", async ({ event, context }) => {
  // upsert "allowance".
  await context.db
    .insert(allowance)
    .values({
      spender: event.args.spender,
      owner: event.args.owner,
      amount: event.args.amount,
    })
    .onConflictDoUpdate({ amount: event.args.amount });

  // add row to "approval_event".
  await context.db.insert(approvalEvent).values({
    id: event.id,
    amount: event.args.amount,
    timestamp: Number(event.block.timestamp),
    owner: event.args.owner,
    spender: event.args.spender,
  });
});
```

With a naive implementation, each database function call requires 1-2 queries. Database queries can take from 1ms to 100ms (because of roundtrip latency), total throughput of Ponder is quickly limited.

To solve this, we implemented an in-memory caching layer on top of the database. The in-memory cache serves as a buffer for database writes that periodically flushes to the database using the [COPY statement](https://www.postgresql.org/docs/current/sql-copy.html). The in-memory cache also saves results of previous queries for reading data without having to make a database query. 

<Callout type="info"> 
  The key-value design of the store API is a requirement. A more expressive syntax such as raw SQL is unable to benefit from the optimization described here.
</Callout>

This was released in [v0.4.37](https://github.com/ponder-sh/ponder/pull/929). After this change, database function calls with a proper cache hit take single digit microseconds.

```
│ Event          │ Count │ Duration (ms) │
├────────────────┼───────┼───────────────┤
│ ERC20:Transfer │ 13332 │         0.008 │
│ ERC20:Approval │  4274 │         0.005 │
```

As with everything, some tradeoffs had to be made. This design uses way more memory, requiring a memory management solution to avoid out-of-memory errors for large apps. More on this later.

### Delayed errors

Let's take a deep dive into the `db.insert()` function call. When there are no "on conflict" modifiers, this function should throw an error if a row with the same primary key already exists in the database because the primary key imposes a unique constraint. In order to check if row exists or not, Ponder needs to check the previously described in-memory cache or maybe do a database query if the row is not in the cache.

Unfortunately, this is really bad for performance. It is especially bad when you consider that this query is almost always wasted work. Only a tiny fraction of apps have a logical error that would cause a unique key constraint.

The solution we came up with is to delay errors until the underlying rows are batched inserted into the database. If an error occurs when inserting the batch, we use binary search to determine exactly which row violates the unique constraint. With this, errors are slightly delayed but still contain all the information for debugging.

This was released in [v0.9.20](https://github.com/ponder-sh/ponder/pull/1522). The Uniswap v4 app got 10x faster because of this optimization.

<img src="/uniswap.png" className="mt-6" />

### Speculation

As previously mentioned, Ponder maintains an in-memory database cache. What happens when the cache gets too large? At first we used a simple LRU algorithm to evict database rows. Because of the inherent randomness of onchain events, a simple LRU algorithm is suboptimal and leads to a low cache hit rate.

Drawing inspiration from [JavaScript engines](https://webkit.org/blog/10308/speculation-in-javascriptcore/), we implemented a speculative cache eviction and pre-fetching algorithm.

The algorithm works as follows:
1. **Profile**: Profile the database accesses of indexing functions.
2. **Predict**: Before indexing a new batch of events, use the profiling data to predict which database rows will be accessed.
3. **Evict and prefetch**: Based on the predictions, evict rows that are no longer needed and prefetch the predicted rows.

This solution is directly applicable to RPC requests made with `context.client` as well. The same profiling, prediction, and prefetching is used to prefetch RPC requests.

This was released in [v0.10.8](https://github.com/ponder-sh/ponder/pull/1596) and [v0.10.15](https://github.com/ponder-sh/ponder/pull/1628). The BasePaint app got 6x faster and acheived a 100% cache hit rate because of this optimization.

<img src="/basepaint.png" className="mt-6" />

## What didn't work

It's also important to consider what didn't work and what can be learned from it. From version v0.2 to v0.4, we implemented a static analysis feature to parse user code and extract the tables that each function reads and writes to. Ponder would use this information to run indexing functions out of order, sometimes multiple at a time. 

While theoretically this would be faster than a single stream of events, it was very complex and fragile. We had many regressions and the dynamic, concurrent nature made it very difficult to debug. Luckily, we were able to take a step back and realize we were not getting the results that we wanted and ended up removing the feature entirely.

## Future optimizations

There are still many ways to make Ponder even faster. Some ideas are:

+ **Multi-threading**: NodeJS is single threaded.
+ **Improved pipeline**: Each step of the ETL can be performed at the same time. Only the slowest step should be the overall bottleneck.
+ **Column selection**: Most data (`block.logsBloom`, `transaction.input`) passed to indexing functions is unused and therefore wasted.
+ **Node-API**: Computationally expensive functions such as `checksumAddress` can benefit from native code.

If any of these ideas excite you, please checkout our github https://github.com/ponder-sh/ponder or reach out to jobs@ponder.sh.