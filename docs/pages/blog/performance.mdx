---
title: "Ponder Performance"
description: "A blog post about performance in Ponder."
---

import { Benchmarks } from "@/components/Benchmarks";
import { Callout } from "nextra/components";


# Ponder Performance

Throughout the almost 3 year history of Ponder and especially over the last several months, performance has been a requirement. We're happy to share what makes Ponder fast and what we learned along the way.

```
Ponder    █ 41s (95.2x faster)

The Graph ██████████████████████████████████████████████████████ 1h 5m 
```

Performance is very important for a framework like Ponder, because it allows developers to rapidly and freely iterate, focusing on their business logic instead of restraints introduced by the tool. Over time, this creates faster feedback loops and better end user expiriences. [give example / talk about where ponder sits in the tech stack]

Ponder is built with Typescript. [mention rust]

We use a combination of unit benchmarks, metrics, and flamegraphs to identify performance bottlenecks and measure the impact of changes.

## Overview of Ponder architecture

To start, a review of the architecture of Ponder. Ponder is an [ETL framework](https://en.wikipedia.org/wiki/Extract,_transform,_load). It **extracts** data from an Ethereum node through the JSON-RPC API, **transforms** the data with user-defined indexing functions, and **loads** the results into postgres for persistent storage.

Internally, a Ponder app has two main phases. The **historical backfill** indexes events from the desiginated "start" of the app up to the current point in time. Then, the **realtime** phase indexes newly produced blocks, processing them immediately.

[explain blocking, critical path]

## In-memory indexing

The transform step of involves running user-defined indexing functions, such as the one from our [ERC20 example](https://github.com/ponder-sh/ponder/blob/main/examples/reference-erc20/src/index.ts) below. An indexing function commonly has one or many database function calls for writing application ready data to the database.

Ponder has a [store API](https://ponder.sh/docs/indexing/write-to-the-database#store-api) for simplified database access. If that is too constrained, [raw SQL](https://ponder.sh/docs/indexing/write-to-the-database#raw-sql) is also available.

```ts filename="src/index.ts" {6, 16}
import { ponder } from "ponder:registry";
import { allowance, approvalEvent } from "ponder:schema";

ponder.on("ERC20:Approval", async ({ event, context }) => {
  // upsert "allowance".
  await context.db
    .insert(allowance)
    .values({
      spender: event.args.spender,
      owner: event.args.owner,
      amount: event.args.amount,
    })
    .onConflictDoUpdate({ amount: event.args.amount });

  // add row to "approval_event".
  await context.db.insert(approvalEvent).values({
    id: event.id,
    amount: event.args.amount,
    timestamp: Number(event.block.timestamp),
    owner: event.args.owner,
    spender: event.args.spender,
  });
});
```

With a naive implementation, each database function call requires 1-2 queries. Database queries take from 1ms to 100ms (because of roundtrip latency), total throughput of Ponder is quickly limited.

To solve this, we implemented an in-memory caching layer on top of the database. The in-memory cache serves as a buffer for database writes that periodically flushes to the database using the [COPY statement](https://www.postgresql.org/docs/current/sql-copy.html). The in-memory cache also saves results of previous queries for reading data without having to make a database query. 

<Callout type="info"> 
 [key-value], a more expressive syntax such as raw SQL is unable to benefit from the optimization described here.
</Callout>

This was released in [v0.4.37](https://github.com/ponder-sh/ponder/pull/929). After this change, database function calls with a proper cache hit take single digit microseconds.

```
│ Event          │ Count │ Duration (ms) │
├────────────────┼───────┼───────────────┤
│ ERC20:Transfer │ 13332 │         0.009 │
│ ERC20:Approval │  4274 │         0.006 │
```

As with everything, some tradeoffs had to be made. This design uses way more memory, requiring a memory management solution to avoid out-of-memory errors for large apps. More on this later.

## Delayed errors

Let's take a deep dive into the `db.insert()` function call. When there are no "on conflict" modifiers, this function should throw an error if a row with the same primary key already exists in the database because the primary key imposes a unique constraint. In order to check if row exists or not, Ponder needs to check the previously described in-memory cache or maybe do a database query if the row is not in the cache.

Unfortunately, this is really bad for performance. It is especially bad when you consider that it is almost always wasted work. Only a tiny fraction of apps have a logical error that would cause a unique key constraint.

The solution we came up with is to delay errors until the underlying rows are batched inserted into the database. For each row, we save some metadata [for errors]. If an error occurs when inserting the batch, we use binary search to determine exactly which row violates the unique constraint. With this, errors are slightly delayed but still contain all the information for debugging.

This was released in [v0.9.20](https://github.com/ponder-sh/ponder/pull/1522). The Uniswap v4 app got 10x faster because of this optimization.

<img src="/uniswap.png" className="mt-10" />

## Speculation

## What didn't work

It's also important to consider what didn't work and what can be learned from it. From version v0.2 to v0.4, we implemented a static analysis feature to parse user code and extract the tables that each function reads and writes to. Ponder would use this information to run indexing functions out of order, sometimes multiple at a time. 

While theoretically this would be faster than a single stream of events, it was very complex and fragile. We had many regressions and the dynamic, concurrent nature made it very difficult to debug. Luckily, we were able to take a step back and realize we were not getting the results that we wanted and ended up removing the feature entirely.

## Future optimizations

There are still many ways to make Ponder even faster. Some ideas are:

+ **Multi-threading**: NodeJS is single threaded.
+ **Improved pipeline**: Each step of the ETL can be performed at the same time. Only the slowest step should be the overall bottleneck.
+ **Column selection**: Most data (`block.logsBloom`, `transaction.input`) passed to indexing functions is unused and therefore wasted.
+ **Node-API**: Computationally expensive functions such as `checksumAddress` can benefit from native code.

If any of these ideas excite you, please checkout our github https://github.com/ponder-sh/ponder or reach out to jobs@ponder.sh.